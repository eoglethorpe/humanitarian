{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"for pulling down data from hr.info API on response level and sending to CSV\"\"\"\n",
    "\n",
    "import urllib.request, json\n",
    "import csv\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "import grequests\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pulling data\n",
    "\n",
    "def pull_indiv_rw(data):\n",
    "    \"\"\"\n",
    "    return all individual crisis data, exclude ones that don't have a 200 status code.\n",
    "    \n",
    "    pull into a df and return, then that gets merged with the existing df\n",
    "    \"\"\"\n",
    "    hrefz = data['rw_gen.href']\n",
    "\n",
    "    def exception_handler(request, exception):\n",
    "         print('Bad URL for ' + request)\n",
    "\n",
    "    resps = []\n",
    "    it = 200\n",
    "    for v in range(0, len(hrefz), it):\n",
    "        print('Pulling individual for hrefs to ' + str(v))\n",
    "        rs = (grequests.get(ref) for ref in hrefz[v : v+it])\n",
    "        resps += grequests.map(rs, exception_handler = exception_handler)\n",
    "    \n",
    "    resps = [json.loads(r.content) for r in resps if r.status_code == 200]\n",
    "        \n",
    "    return json_normalize(resps)[['data', 'href', 'totalCount']].add_prefix('rw_gen.')\n",
    "#     return json_normalize(resps, ['totalCount', 'data', 'href']).add_prefix('rw_gen.')\n",
    "\n",
    "def fetch_api_rw(maxv = None):\n",
    "    \"\"\"\n",
    "    pull down all API info for RW general crisis and return as dataframe.\n",
    "    \n",
    "    maxv = (start_val, end_val)\n",
    "    \"\"\"\n",
    "    data = []    \n",
    "    \n",
    "    if maxv:\n",
    "        start = maxv[0]\n",
    "        fin = maxv[1]\n",
    "        step = min(fin - start, 1000)\n",
    "    \n",
    "    else:\n",
    "        start = 0\n",
    "        fin = json.loads(urllib.request.urlopen(\"https://api.reliefweb.int/v1/\" \\\n",
    "                                   \"disasters?appname=vocabulary&preset=external\").read().decode())['totalCount']\n",
    "        step = 1000\n",
    "        \n",
    "    for i in range(start, fin, step):\n",
    "        with urllib.request.urlopen(\"https://api.reliefweb.int/v1/disasters?appname=vocabulary\"\n",
    "                                    \"&preset=external&limit={0}&offset={1}\"\n",
    "                                    .format(min(step, fin - i), i)) as url:\n",
    "            data += json.loads(url.read().decode())['data']\n",
    "\n",
    "\n",
    "    ret = json_normalize(data).add_prefix('rw_gen.')\n",
    "    \n",
    "    assert(len(ret) == fin - start)\n",
    "    print('pulling down from rw entry count of: ' + str(len(ret)))\n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3021\n",
      "pulling down from rw entry count of: 3021\n",
      "trim data length: 1701\n",
      "Pulling individual for hrefs to 0\n",
      "Pulling individual for hrefs to 200\n",
      "Pulling individual for hrefs to 400\n",
      "Pulling individual for hrefs to 600\n",
      "Pulling individual for hrefs to 800\n",
      "Pulling individual for hrefs to 1000\n",
      "Pulling individual for hrefs to 1200\n",
      "Pulling individual for hrefs to 1400\n",
      "Pulling individual for hrefs to 1600\n"
     ]
    }
   ],
   "source": [
    "nd = rw(test = None, year = 2005)\n",
    "\n",
    "r = nd.master_pull()\n",
    "\n",
    "r.to_csv('rw_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class rw(object):\n",
    "    \n",
    "    def __init__(self, test, year):\n",
    "        self.test = test\n",
    "        self.data = None\n",
    "        self.year = year\n",
    "\n",
    "    def extract_date(self, val):\n",
    "        name = val.replace(' ', '')[-7:]\n",
    "        month = None\n",
    "        year = None\n",
    "\n",
    "        MIN_YEAR = 2005\n",
    "        #if we don't have regular formatting, take just year\n",
    "        if not name[0:3].isalpha():\n",
    "            if not name[-4:].isnumeric():\n",
    "                print(\"***bad year: \" + name)\n",
    "            else:\n",
    "                year = int(name[-4:])\n",
    "        else:\n",
    "            month = name[:3]\n",
    "            year = int(name[-4:])\n",
    "\n",
    "        if year:\n",
    "            if year >= MIN_YEAR:\n",
    "                return [month, year]\n",
    "\n",
    "        return (None, None)\n",
    "\n",
    "    def get_date(self):\n",
    "        self.data['rw_gen.month'] = None\n",
    "        self.data['rw_gen.year'] = None\n",
    "        self.data[['rw_gen.month', 'rw_gen.year']] = self.data.apply(lambda x: \n",
    "                                                            pd.Series(self.extract_date(x['rw_gen.fields.name'])), axis = 1)\n",
    "\n",
    "        self.data = self.data[pd.notnull(self.data['rw_gen.year'])]\n",
    "        self.data['rw_gen.year'] = self.data['rw_gen.year'].astype(int)\n",
    "\n",
    "    def trim_nm(self):\n",
    "\n",
    "        def trim(v):\n",
    "            s_val = None\n",
    "\n",
    "            if len(v.split('-')) != 1:\n",
    "                s_val = '-'\n",
    "            elif len(v.split('–')) != 1:\n",
    "                s_val = '–' \n",
    "\n",
    "            if s_val:\n",
    "                return v.split(s_val)[0]\n",
    "            else:\n",
    "                return v\n",
    "\n",
    "        self.data['rw_gen.fields.name'] = self.data.apply(lambda x: trim(x['rw_gen.fields.name']), axis = 1)\n",
    "\n",
    "    def rm_old(self):\n",
    "        self.data = self.data.drop(self.data[self.data['rw_gen.year'] < self.year].index)\n",
    "        print('trim data length: ' + str(len(self.data)))\n",
    "\n",
    "    def _get_spec_crisis_lamb(self, v):\n",
    "        ret = []\n",
    "\n",
    "        if v['rw_gen.totalCount'] != 1:\n",
    "            print('***wrong totalCount ' + str(v))\n",
    "\n",
    "        j = json_normalize(v['rw_gen.data'][0])\n",
    "\n",
    "        #add in top level data compents\n",
    "        try:\n",
    "            ret += [j[ent.split('data.')[1]][0] for ent in self.new_cols_top]\n",
    "            \n",
    "        except:\n",
    "            ret += [None] * len(self.new_cols_top)\n",
    "\n",
    "        #add in data.fields info. entry be like:\n",
    "        \"\"\"\n",
    "            {'href': 'https://api.reliefweb.int/v1/countries/255',\n",
    "             'id': 255,\n",
    "             'iso3': 'yem',\n",
    "             'location': {'lat': 15.94, 'lon': 47.62},\n",
    "             'name': 'Yemen',\n",
    "             'primary': True}\n",
    "            primary = None\n",
    "        \"\"\"\n",
    "        \n",
    "        #add in other columns\n",
    "        for v in j['fields.country'][0]:\n",
    "            if 'primary' in v:\n",
    "                primary = v\n",
    "                break        \n",
    "\n",
    "        #bad news if no primary\n",
    "        if not primary:\n",
    "            print('*** no primary! ' + str(v))\n",
    "            ret = [None] * (len(self.all_cols) - len(self.new_cols_top))\n",
    "            \n",
    "        else:\n",
    "            try:\n",
    "                rollback = ret\n",
    "                \n",
    "                #also add in other cols\n",
    "                ret.append(len(j['fields.country'][0]))\n",
    "\n",
    "                ret += [primary[c] for c in ['name', 'iso3', 'href']]\n",
    "                ret.append(primary['location']['lat'])\n",
    "                ret.append(primary['location']['lon'])\n",
    "                \n",
    "            except:\n",
    "                ret = rollback + [None] * (len(rollback) - (len(self.all_cols) - len(self.new_cols_top)))\n",
    "        \n",
    "        return ret\n",
    "    \n",
    "    def get_spec_crisis(self):\n",
    "        \"\"\"\n",
    "        merge relevant crisis level data\n",
    "        \"\"\"\n",
    "        \n",
    "        l = pull_indiv_rw(self.data)\n",
    "        \n",
    "        l['rw_gen.totalCount'] = l['rw_gen.totalCount'].astype(int)\n",
    "\n",
    "        self.new_cols_top = ['data.fields.description',\n",
    "                    'data.fields.url_alias']\n",
    "\n",
    "        self.other_cols = ['num_country']\n",
    "        \n",
    "        self.new_cols_country = ['data.fields.country.name', \n",
    "                            'data.fields.country.iso', \n",
    "                            'data.fields.country.href',\n",
    "                            'data.fields.country.location_lat', \n",
    "                            'data.fields.country.location_long']\n",
    "\n",
    "        self.all_cols = self.new_cols_top + self.other_cols + self.new_cols_country\n",
    "\n",
    "        for v in self.all_cols:\n",
    "            l[v] = None\n",
    "        \n",
    "        l[self.all_cols] = l.apply(lambda x : pd.Series(self._get_spec_crisis_lamb(x)), axis = 1)\n",
    "\n",
    "        #drop unnecessary columns, cleanup\n",
    "        l = l.drop('rw_gen.data', axis = 1)\n",
    "        l = l.drop('rw_gen.totalCount', axis = 1)\n",
    "        l['num_country'] = l['num_country'].astype(int)\n",
    "\n",
    "        self.data = self.data.merge(l, how = 'left', on = 'rw_gen.href')\n",
    "        \n",
    "    def master_pull(self):\n",
    "        \"\"\"take crises only after certain year, add month_crisis: mmm, and year_crisis: yyyy to each crisis's entry\n",
    "\n",
    "            names are either in format of:\n",
    "                MMM YYYY\n",
    "                OR\n",
    "                YYYY-YYYY\n",
    "\n",
    "            if not in first format, check to see if end year > 2005\n",
    "        \"\"\"\n",
    "        #only pull some data if test\n",
    "        if self.test:\n",
    "            self.data = fetch_api_rw(self.test)\n",
    "        else:\n",
    "            self.data = fetch_api_rw()\n",
    "\n",
    "        #do things to primary rw data\n",
    "        self.get_date()\n",
    "        self.rm_old()\n",
    "        self.trim_nm()\n",
    "        \n",
    "        #do crisiswise pull\n",
    "        self.get_spec_crisis()\n",
    "        \n",
    "        return self.data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
